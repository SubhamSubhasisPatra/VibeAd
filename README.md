# Whisper Live Dictation

Real-time, fully offline speech-to-text using [whisper.cpp](https://github.com/ggerganov/whisper.cpp) with models downloaded **exclusively from the official OpenAI Azure CDN**.

> **Zero HuggingFace dependencies.** Every model byte comes from
> `https://openaipublic.azureedge.net` — the official OpenAI distribution endpoint.
> HuggingFace domains are explicitly blocked at the network layer in every script.

---

## How It Works

```
OpenAI Azure CDN ──→ tiny.en.pt (original PyTorch model, ~75 MB)
                          │
                          ▼
        python convert-pt-to-ggml.py  ← from whisper.cpp repo (pure Python)
                          │
                          ▼
                  ggml-tiny.en.bin    ← whisper.cpp format, used at runtime
                          │
                          ▼
                   whisper-stream     ← C/C++ binary, captures mic via SDL2
                          │
                          ▼
              Real-time transcription (sub-400ms latency)
```

After setup, the runtime is **pure C/C++** — no Python, no PyTorch, no GPU required.

---

## Project Structure

Everything is self-contained within this repository:

```
VibeAd/
├── README.md                         ← this file
├── requirements.txt                  ← Python deps for PyTorch dictation (Option 2)
├── whisper_hotkey_dictation.py       ← PyTorch-based dictation (Option 2)
│
├── scripts/
│   ├── setup.py                      ← cross-platform setup (download, convert, build)
│   ├── setup-mac.sh                  ← macOS one-liner wrapper
│   ├── setup-windows.ps1             ← Windows one-liner wrapper
│   └── whisper_live.py               ← optional Python wrapper for stream binary
│
├── run-live.sh                       ← macOS launcher (generated by setup)
├── run-live-fast.sh                  ← macOS fast launcher (generated by setup)
├── run-live.ps1                      ← Windows launcher (generated by setup)
├── run-live-fast.ps1                 ← Windows fast launcher (generated by setup)
│
└── local/                            ← ALL build artifacts (gitignored)
    ├── whisper.cpp/                  ← shallow clone (conversion scripts + source)
    ├── models/
    │   ├── tiny.en.pt                ← original OpenAI model
    │   └── ggml-tiny.en.bin          ← converted GGML model
    └── bin/
        ├── whisper-stream            ← live transcription binary
        ├── whisper-cli               ← file transcription binary
        ├── whisper-quantize          ← model quantization tool
        └── lib*.dylib                ← shared libraries (macOS)
```

The `local/` directory and the generated `run-live*` launcher scripts are **gitignored** — only the source scripts and configuration are committed.

---

## Option 1 — whisper-live via whisper.cpp (Recommended)

### Prerequisites

| Tool | macOS | Windows |
|------|-------|---------|
| **git** | `xcode-select --install` | [git-scm.com](https://git-scm.com/download/win) or `winget install Git.Git` |
| **Python 3.10–3.13** | `brew install python@3.13` | [python.org](https://www.python.org/downloads/) (check "Add to PATH") |
| **cmake** | `brew install cmake` | [cmake.org](https://cmake.org/download/) or Visual Studio Build Tools |
| **SDL2** | `brew install sdl2` | *(only needed if building from source)* |
| **C/C++ compiler** | Xcode CLT (comes with git) | Visual Studio Build Tools *(only if building)* |

> **Note:** Python, torch, numpy, and openai-whisper are only needed **once** during setup for the `.pt → ggml` conversion. The setup scripts create a temporary venv that is automatically deleted after conversion. The runtime is pure C/C++.
>
> **cmake** is needed on macOS to build the `whisper-stream` binary from source (no prebuilt macOS/arm64 binary exists in GitHub releases). On **Windows**, prebuilt binaries are downloaded directly — no cmake needed.

### Quick Start — macOS

```sh
# One-time setup
cd scripts
chmod +x setup-mac.sh
./setup-mac.sh

# Run live transcription (from project root)
cd ..
./run-live.sh

# Ultra-low-latency
./run-live-fast.sh
```

### Quick Start — Windows (PowerShell)

```powershell
# One-time setup
cd scripts
.\setup-windows.ps1

# Run live transcription (from project root)
cd ..
.\run-live.ps1

# Ultra-low-latency
.\run-live-fast.ps1

# Or use the .bat file
run-live.bat
```

### Setup Options

Both setup scripts accept the same flags:

| Flag | Default | Description |
|------|---------|-------------|
| `--model` | `tiny.en` | Model name (see table below) |
| `--quantize` | *(none)* | Quantization: `q8_0`, `q5_0`, `q5_1`, `q4_0`, `q4_1` |

```sh
# macOS — base model with quantization
./setup-mac.sh --model base.en --quantize q8_0

# Windows — small model, quantized
.\setup-windows.ps1 -Model small.en -Quantize q5_0
```

### Available Models (All from OpenAI Azure CDN)

| Model | English-Only | Size (.pt) | Speed | Quality |
|-------|-------------|------------|-------|---------|
| `tiny.en` | ✓ | ~75 MB | ★★★★★ | ★★☆☆☆ |
| `tiny` | Multilingual | ~75 MB | ★★★★★ | ★★☆☆☆ |
| `base.en` | ✓ | ~142 MB | ★★★★☆ | ★★★☆☆ |
| `base` | Multilingual | ~142 MB | ★★★★☆ | ★★★☆☆ |
| `small.en` | ✓ | ~466 MB | ★★★☆☆ | ★★★★☆ |
| `small` | Multilingual | ~466 MB | ★★★☆☆ | ★★★★☆ |
| `medium.en` | ✓ | ~1.5 GB | ★★☆☆☆ | ★★★★★ |
| `medium` | Multilingual | ~1.5 GB | ★★☆☆☆ | ★★★★★ |
| `large-v3` | Multilingual | ~3.1 GB | ★☆☆☆☆ | ★★★★★ |

For live transcription on CPU, **`tiny.en`** or **`base.en`** with `q8_0` quantization is recommended.

### What the Setup Actually Does

Here's the exact flow — no magic:

```
Step 1:  git clone --depth 1 https://github.com/ggerganov/whisper.cpp
         → gets conversion script + C++ source

Step 2:  curl https://openaipublic.azureedge.net/.../tiny.en.pt
         → downloads official OpenAI model, verifies SHA256

Step 3:  python convert-pt-to-ggml.py tiny.en.pt ...
         → pure Python conversion (needs torch + openai-whisper in temp venv)
         → produces ggml-tiny.en.bin

Step 4:  cmake + make  (macOS only — Windows downloads prebuilt binary)
         → builds whisper-stream from the same clone
         → this is the ONLY step that needs cmake

Done:    local/bin/whisper-stream + local/models/ggml-tiny.en.bin
         → run with ./run-live.sh
```

### Python Wrapper (Optional)

A Python wrapper (`scripts/whisper_live.py`) adds transcript filtering, hotkey toggle, and auto-typing. It's entirely optional.

```sh
# Basic
python scripts/whisper_live.py

# Type output into the focused window
python scripts/whisper_live.py --type-output

# Ultra-low-latency with hotkey toggle
python scripts/whisper_live.py --step 300 --length 3000 --hotkey '<cmd>+<shift>+g'

# List audio devices
python scripts/whisper_live.py --list-devices

# Pick a specific mic
python scripts/whisper_live.py --capture 2
```

Optional Python deps (only for the wrapper, not for the core stream):
```sh
pip install pynput        # for --type-output / --hotkey
pip install sounddevice   # for --list-devices
```

---

## Option 2 — Whisper Hotkey Dictation (PyTorch)

Python-based dictation using the `openai-whisper` package. Runs entirely in Python with PyTorch inference. Heavier than whisper.cpp but useful if you want to modify the transcription pipeline in Python.

### Setup

```sh
python3 -m venv venv
source venv/bin/activate    # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Run

```sh
python whisper_hotkey_dictation.py --model base
```

Default hotkeys:
- **macOS:** `Command + Shift + G`
- **Windows:** `Alt + Ctrl + Shift + M`

See `python whisper_hotkey_dictation.py --help` for all options.

---

## Why whisper.cpp Over PyTorch

| | PyTorch Runtime | whisper.cpp (GGML) |
|---|---|---|
| Language | Python + C++ (CUDA) | Pure C/C++ |
| Overhead | Autograd, GIL, interpreter | None |
| Memory | ~500 MB+ runtime | ~50 MB (with q8_0) |
| SIMD | Generic kernels | AVX/AVX2/NEON/Metal |
| Quantization | Not built-in | q8_0, q5_0, q4_0, etc. |
| Startup | 2–5 seconds | < 0.5 seconds |
| Model size (tiny.en) | ~75 MB (float32) | ~40 MB (q8_0) |

---

## Performance Tuning

### Stream Parameters

| Parameter | Flag | Effect |
|-----------|------|--------|
| Step size | `--step` | Lower = lower latency, higher CPU. `300` fast, `500` balanced |
| Buffer length | `--length` | Longer = better accuracy. `3000`–`5000` recommended |
| Keep | `--keep` | Overlap from previous step. `200` is good for continuity |
| Threads | `--threads` | More = faster, but diminishing returns past 4–8 |

### Recommended Presets

**Balanced (default — `run-live.sh`):**
```
--step 500 --length 5000 --threads 8
```

**Ultra-low-latency (`run-live-fast.sh`):**
```
--step 300 --length 3000 --keep 200 --threads 8
```

---

## Security & Privacy

- **Fully offline** after initial setup — no network calls during transcription
- **No telemetry** — whisper.cpp is open-source C/C++
- **No cloud APIs** — all processing on your local CPU/GPU
- **No HuggingFace** — models only from `openaipublic.azureedge.net`
- **SHA256 verified** — checksums embedded in download URLs are checked automatically
- Audio never leaves your machine

### Blocked Domains

Every setup script explicitly blocks downloads from:
- `huggingface.co`, `hf.co`, `hf-mirror.com`
- `cdn-lfs.huggingface.co`, `cdn-lfs.hf.co`

Any attempt to fetch from these domains hard-fails with an error.

---

## Troubleshooting

### Microphone not working (macOS)
System Settings → Privacy & Security → Microphone → enable for your terminal app.

### Microphone not working (Windows)
Settings → Privacy → Microphone → Allow apps to access your microphone.

### "stream binary not found"
Run the setup script first (`cd scripts && ./setup-mac.sh` or `.\setup-windows.ps1`).

### cmake not found (macOS)
```sh
brew install cmake
```

### SDL2 not found (macOS)
```sh
brew install sdl2
```

### DLL errors (Windows)
Install the [Visual C++ Redistributable](https://aka.ms/vs/17/release/vc_redist.x64.exe).

### High CPU / latency
- Use `tiny.en` with `q8_0` quantization
- Reduce threads: `--threads 2`
- Increase step: `--step 1000`

---

## License

whisper.cpp — MIT License
OpenAI Whisper models — MIT License